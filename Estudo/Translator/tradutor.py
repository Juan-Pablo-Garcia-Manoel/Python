# -*- coding: utf-8 -*-
"""tradutor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BarMvDtjeTLJt4o-jKayAZ36-cGwkxJI
"""

!pip install requests python-docx

from ast import Return
import requests
from docx import Document
import os

subscription_key = ""
endpoint = ''
location = ""
language_destination = 'en'

path = '/translate'
constructedurl = endpoint + path

def translator_text(text,target_language):
  path = '/translate'
  constructedurl = endpoint + path
  headers = {
      'Ocp-Apim-Subscription-key':subscription_key,
      'Ocp-Apim-Subscription-Region':location,
      'Content-type':'application/json',
      'X-ClientTraceId':str(os.urandom(16))
  }

  body = [{
    'text':text
  }]
  params = {
      'api-version': '3.0',
      'from':'pt-br',
      'to': [target_language]
  }
  request = requests.post(constructedurl,params=params, headers=headers, json=body)
  response = request.json()
  return response[0]["translations"][0]["text"]

def translate_document(path):
  document = Document(path)
  full_text = []
  for paragraph in document.paragraphs:
    translated_text = translator_text(paragraph.text, language_destination)
    full_text.append(translated_text)

  translated_doc = Document()
  for line in full_text:
    translated_doc.add_paragraph(line)
  path_translated = path.replace(".docx", f"_{language_destination}.docx")
  translated_doc.save(path_translated)
  return path_translated

!pip install requests beautifulsoup4 openai langchain-openai

import requests
from bs4 import BeautifulSoup

def extract_text_from_url(url):
  response = requests.get(url)

  if response.status_code == 200:
    soup = BeautifulSoup(response.text,'html.parser')
    for script_or_style in soup(['script','style']):
      script_or_style.decompose()
    texto = soup.get_text(separator=' ')
    #Limpar texto
    linhas = (line.strip() for line in texto.splitlines())
    parts = (phrase.strip() for line in linhas for phrase in line.split(" "))
    texto_limpo = '\n'.join(part for part in parts if part)
    return texto_limpo
  else:
    print(f"Failed to fetch the URL. Status code: {response.status_code}")
    return None
  text = soup.get_text()
  return text

extract_text_from_url('https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo')

from langchain_openai.chat_models.azure import AzureChatOpenAI

client = AzureChatOpenAI(
    azure_endpoint ="",
    api_key ="",
    api_version = "",
    deployment_name="",
    max_retries = 0
)

def translate_article(text, lang):
  messages = [
      ("system" , "Você atua como tradutor de textos"),
      ("user", f"Traduza o {text} para o idioma {lang} e responda em markdown")
  ]

  response = client.invoke(messages)
  print(response.content)
  return response.content

translate_article("Let's see if the deployment was succeeded.","portugues")

url = 'https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo'
text = extract_text_from_url(url)
article = translate_article(text,"pt-br")
print(article)



translator_text("Quem me dera, ao menos uma vez",language_destination)

input_file = "/content/Indios - Legião Urbana.docx"
translate_document(input_file)